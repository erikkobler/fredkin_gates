{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T16:18:10.248414Z",
     "start_time": "2025-09-16T16:18:10.244740Z"
    }
   },
   "source": [
    "from pyexpat import model\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from scipy._lib.array_api_compat import device\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T16:29:49.225083Z",
     "start_time": "2025-09-16T16:29:49.218652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FredkinLayer(torch.nn.Module):\n",
    "    M3 = torch.tensor([[0,0,0,0,1],\n",
    "                       [0,1,1,-1,0],\n",
    "                       [1,0,-1,1,0]\n",
    "                       ])\n",
    "    \n",
    "    def __init__(self,din:int,dout:int,device:str='cpu',seed:int=None):\n",
    "        super().__init__()\n",
    "        self.din = din\n",
    "        #assert dout % 3 == 0 , \"number of outputs must be divisible by 3\"\n",
    "        self.dout = dout\n",
    "        self.device = device\n",
    "        #self.wgts = torch.nn.Parameter(torch.randn(dout,din,device=device),requires_grad=True) #learnable params\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "        self.roles = torch.stack([torch.randperm(3) for _ in range(dout)],dim=0)        #(dout , 3)\n",
    "        #\n",
    "        init_w = self._ordered_initial_weights(din, dout)  # (dout, din), rows sum to 1\n",
    "        init_logits = torch.log(init_w + 1e-12)\n",
    "        self.wgts_logits = torch.nn.Parameter(init_logits.to(self.device), requires_grad=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    def _ordered_initial_weights(self, din, dout , top3_prob=0.6):\n",
    "        \"\"\"\n",
    "        Build (dout, din) where for neuron i the three preferred indices\n",
    "        are start=(i*3) % din, start+1, start+2 (wrapping).\n",
    "        Those three get top3_prob/3 each (top3_prob total). Remaining din-3 share (1-top3_prob) uniformly.\n",
    "        Rows sum to 1.\n",
    "        \"\"\"\n",
    "        assert top3_prob > 0 and top3_prob <= 1.0\n",
    "        init = torch.zeros((dout, din), dtype=torch.float32)\n",
    "        if din <= 3:\n",
    "            # edge case: if din <=3, just distribute evenly among available features\n",
    "            init[:] = 1.0 / din\n",
    "            return init\n",
    "\n",
    "        rem_share = (1-top3_prob) / (din - 3)\n",
    "        for i in range(dout):\n",
    "            start = (i * 3) % din\n",
    "            chosen = [(start + k) % din for k in range(3)]\n",
    "            for j in range(din):\n",
    "                if j in chosen:\n",
    "                    init[i, j] = top3_prob/3\n",
    "                else:\n",
    "                    init[i, j] = rem_share\n",
    "        # numerical safety: renormalize rows to sum exactly to 1\n",
    "        init = init / init.sum(dim=1, keepdim=True)\n",
    "        return init\n",
    "    \n",
    "    def forward(self,x:torch.Tensor):\n",
    "        batch_size = x.shape[0]\n",
    "        assert x.shape[-1] == self.din\n",
    "        \n",
    "        # compute normalized, non-negative weights per neuron (rows sum to 1)\n",
    "        wgts = F.softmax(self.wgts_logits, dim=1)  # (dout, din)\n",
    "        \n",
    "        #hard selection of top 3 inputs for each gate\n",
    "        top_vals , top_idx = torch.topk(wgts,k=3,dim=1) #(dout,3)\n",
    "        \n",
    "        #create mask for Straight through estimator\n",
    "        mask = torch.zeros_like(wgts)\n",
    "        mask.scatter_(1,top_idx,1.0)\n",
    "        ste_mask = mask + wgts - wgts.detach()\n",
    "        \n",
    "        #replicate inputs to match output neurons\n",
    "        x_tiled = x.unsqueeze(1).expand(-1 , self.dout, -1) #(batch_size,dout,din)\n",
    "        \n",
    "        #apply mask\n",
    "        x_selected = ste_mask.unsqueeze(0) * x_tiled\n",
    "        \n",
    "        #collect inputs for fredkin computations\n",
    "        top3_inputs = torch.gather(x_selected,2,top_idx.unsqueeze(0).expand(batch_size,-1,-1)) #(batch_size,dout,3)\n",
    "        roles_idx = self.roles.unsqueeze(0).expand(batch_size, -1, -1)  # (batch_size, dout, 3)\n",
    "        fredkin_inputs = torch.gather(top3_inputs,2,roles_idx) #(batch_size,dout,3)\n",
    "        u,a,b = fredkin_inputs[:,:,0],fredkin_inputs[:,:,1],fredkin_inputs[:,:,2]\n",
    "        #print(\"u[0]:\", u[0].detach().cpu().numpy())\n",
    "        #print(\"a[0]:\", a[0].detach().cpu().numpy())\n",
    "        #print(\"b[0]:\", b[0].detach().cpu().numpy())\n",
    "\n",
    "        \n",
    "        #fredkin computation\n",
    "        v = u\n",
    "        a_out = u*a + (1-u)*b\n",
    "        b_out = u*b + (1-u)*a\n",
    "        out = torch.stack([v , a_out , b_out],dim=-1)\n",
    "        \n",
    "        #flatten output\n",
    "        out = out.reshape(x.size(0),-1)\n",
    "        return out\n",
    "        "
   ],
   "id": "7e10869706283ccd",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#DEBUG HELPER CODE\n",
    "        print(\"shapes:\")\n",
    "        #print(\"x_selected\",x_selected.shape)\n",
    "        print(\"X_tiled\",x_tiled.shape)\n",
    "        print(\"ste_mask\",ste_mask.shape)\n",
    "        print(\"ste_mask_squeezed\",ste_mask.unsqueeze(0).shape)\n",
    "        print(\"weights\",self.wgts.shape)\n",
    "        \n",
    "        print(\"shapes of inputs:\")\n",
    "        print(\"u\",u.shape)\n",
    "        print(\"a\",a.shape)\n",
    "        print(\"b\",b.shape)"
   ],
   "id": "9f44154cda0d3a8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T16:14:11.163882Z",
     "start_time": "2025-09-16T16:14:11.110113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Define some easy training dataset\n",
    "def create_majority_dataset(samplesize = 1000 , n_bits = 9 , p_one=0.5, device='cpu' ):\n",
    "    x = torch.bernoulli(torch.full((samplesize,n_bits) , p_one , device=device)).float()\n",
    "    labels = ( x.sum(dim=1) > (n_bits/2) ).float()\n",
    "    return x,labels\n",
    "\n",
    "x_train,labels_train = create_majority_dataset()\n",
    "x_test,labels_test = create_majority_dataset(samplesize=100,n_bits=9,p_one=0.5)\n",
    "\n",
    "#sneak preview in training data\n",
    "for i in range(max(10,x_train.shape[0])):\n",
    "    print(x_train[i].numpy(),labels_train[i].numpy())\n",
    "\n",
    "train_data = TensorDataset(x_train,labels_train)\n",
    "val_data = TensorDataset(x_test,labels_test)\n"
   ],
   "id": "bc4081364c7d4438",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 1. 0. 1. 0.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 0.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 0. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 1. 0. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 0. 1. 0. 0. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 0.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 1. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[1. 0. 0. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 0. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 1. 0. 0. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0.] 0.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[1. 0. 0. 1. 0. 0. 1. 1. 0.] 0.0\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 1. 1. 1. 0. 1. 0.] 1.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 1.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1.] 1.0\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 1.] 0.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 0. 1. 1.] 1.0\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 0.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0.] 0.0\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 1.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 1.] 0.0\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1.] 0.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0.] 0.0\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 0.] 0.0\n",
      "[0. 1. 0. 0. 0. 1. 1. 0. 1.] 0.0\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 1.] 1.0\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0.] 0.0\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 1.] 1.0\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 1.] 1.0\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 1.] 0.0\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 0.] 1.0\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 0.] 0.0\n",
      "[1. 1. 0. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 1.] 0.0\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 0.] 1.0\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 1.] 1.0\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 1.] 0.0\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 0.] 1.0\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1.] 0.0\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1.] 0.0\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0.] 0.0\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0.] 1.0\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 0.] 1.0\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0.] 1.0\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1.] 0.0\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T16:33:14.015681Z",
     "start_time": "2025-09-16T16:32:35.120787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create model and run training\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "class FredkinNet(torch.nn.Module):\n",
    "    def __init__(self,din,dout):\n",
    "        super().__init__()\n",
    "        self.fred1 = FredkinLayer(din,5,seed=42)\n",
    "        self.fred2 = FredkinLayer(15,5,seed=43)\n",
    "        self.fred3 = FredkinLayer(15,5,seed=44)\n",
    "        self.fred4 = FredkinLayer(15,5,seed=45)\n",
    "        self.fred5 = FredkinLayer(15,5,seed=46)\n",
    "        self.fred6 = FredkinLayer(15,3,seed=47)\n",
    "        self.fred7 = FredkinLayer(9,2,seed=48)\n",
    "        self.fred8 = FredkinLayer(6,1,seed=49)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fred1(x)\n",
    "        out = self.fred2(out)\n",
    "        out = self.fred3(out)\n",
    "        out = self.fred4(out)\n",
    "        out = self.fred5(out)\n",
    "        out = self.fred6(out)\n",
    "        out = self.fred7(out)\n",
    "        out = self.fred8(out)\n",
    "        a_primes = out[:,1::3]     #(batch, dout)\n",
    "        out_summmed = a_primes.sum(dim=1) #(batch,)\n",
    "        return out_summmed\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=4,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=4,shuffle=False)\n",
    "\n",
    "net = FredkinNet(9,15)\n",
    "\n",
    "optim = torch.optim.Adam(net.parameters(),lr=LEARNING_RATE)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(1,NUM_EPOCHS+1):\n",
    "    #TRAIN\n",
    "    net.train()\n",
    "    running_loss =0.0\n",
    "    running_samples = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        \n",
    "        logits = net(x)\n",
    "        loss = criterion(logits,y)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        bs = x.size(0)\n",
    "        running_loss += loss.item()*bs\n",
    "        running_samples += bs\n",
    "    \n",
    "    epoch_loss = running_loss/running_samples\n",
    "    #VALIDATE\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    val_samples = 0\n",
    "    correct =0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            logits = net(x)\n",
    "            loss = criterion(logits,y)\n",
    "            \n",
    "            bs = x.size(0)\n",
    "            val_loss += loss.item()*bs\n",
    "            val_samples += bs\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            correct += (preds == y).float().sum().item()\n",
    "    val_loss = val_loss/val_samples\n",
    "    val_acc = correct / val_samples\n",
    "    print(f\"Epoch {epoch:02d} train_loss = {epoch_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "    \n",
    "        \n",
    "        \n"
   ],
   "id": "fce5713fb96dec3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 train_loss = 0.6684 val_loss=0.6932 val_acc=0.4600\n",
      "Epoch 02 train_loss = 0.6701 val_loss=0.7422 val_acc=0.4600\n",
      "Epoch 03 train_loss = 0.6834 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 04 train_loss = 0.6780 val_loss=0.6932 val_acc=0.4600\n",
      "Epoch 05 train_loss = 0.6749 val_loss=0.7546 val_acc=0.4600\n",
      "Epoch 06 train_loss = 0.6702 val_loss=0.7266 val_acc=0.4600\n",
      "Epoch 07 train_loss = 0.6747 val_loss=0.7756 val_acc=0.4600\n",
      "Epoch 08 train_loss = 0.6713 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 09 train_loss = 0.6836 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 10 train_loss = 0.6708 val_loss=0.7266 val_acc=0.4600\n",
      "Epoch 11 train_loss = 0.6739 val_loss=0.7756 val_acc=0.4600\n",
      "Epoch 12 train_loss = 0.6675 val_loss=0.7246 val_acc=0.4600\n",
      "Epoch 13 train_loss = 0.6712 val_loss=0.7370 val_acc=0.4600\n",
      "Epoch 14 train_loss = 0.6870 val_loss=0.7370 val_acc=0.4600\n",
      "Epoch 15 train_loss = 0.6829 val_loss=0.7370 val_acc=0.4600\n",
      "Epoch 16 train_loss = 0.6849 val_loss=0.7266 val_acc=0.4600\n",
      "Epoch 17 train_loss = 0.6748 val_loss=0.7546 val_acc=0.4600\n",
      "Epoch 18 train_loss = 0.6713 val_loss=0.7266 val_acc=0.4600\n",
      "Epoch 19 train_loss = 0.6753 val_loss=0.7756 val_acc=0.4600\n",
      "Epoch 20 train_loss = 0.6797 val_loss=0.7546 val_acc=0.4600\n",
      "Epoch 21 train_loss = 0.6609 val_loss=0.7546 val_acc=0.4600\n",
      "Epoch 22 train_loss = 0.6654 val_loss=0.7056 val_acc=0.4600\n",
      "Epoch 23 train_loss = 0.6806 val_loss=0.7266 val_acc=0.4600\n",
      "Epoch 24 train_loss = 0.6771 val_loss=0.7370 val_acc=0.4600\n",
      "Epoch 25 train_loss = 0.6670 val_loss=0.7056 val_acc=0.4600\n",
      "Epoch 26 train_loss = 0.6822 val_loss=0.7056 val_acc=0.4600\n",
      "Epoch 27 train_loss = 0.6697 val_loss=0.6932 val_acc=0.4600\n",
      "Epoch 28 train_loss = 0.6759 val_loss=0.6932 val_acc=0.4600\n",
      "Epoch 29 train_loss = 0.6740 val_loss=0.7422 val_acc=0.4600\n",
      "Epoch 30 train_loss = 0.6815 val_loss=0.7370 val_acc=0.4600\n",
      "Epoch 31 train_loss = 0.6772 val_loss=0.7422 val_acc=0.4600\n",
      "Epoch 32 train_loss = 0.6756 val_loss=0.7422 val_acc=0.4600\n",
      "Epoch 33 train_loss = 0.6769 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 34 train_loss = 0.6776 val_loss=0.7508 val_acc=0.4600\n",
      "Epoch 35 train_loss = 0.6887 val_loss=0.7036 val_acc=0.4600\n",
      "Epoch 36 train_loss = 0.6813 val_loss=0.7032 val_acc=0.4600\n",
      "Epoch 37 train_loss = 0.6740 val_loss=0.7132 val_acc=0.4600\n",
      "Epoch 38 train_loss = 0.6670 val_loss=0.7170 val_acc=0.4600\n",
      "Epoch 39 train_loss = 0.6749 val_loss=0.6798 val_acc=0.4600\n",
      "Epoch 40 train_loss = 0.6749 val_loss=0.7756 val_acc=0.4600\n",
      "Epoch 41 train_loss = 0.6763 val_loss=0.7422 val_acc=0.4600\n",
      "Epoch 42 train_loss = 0.6737 val_loss=0.7294 val_acc=0.4600\n",
      "Epoch 43 train_loss = 0.6725 val_loss=0.7556 val_acc=0.4600\n",
      "Epoch 44 train_loss = 0.6927 val_loss=0.7108 val_acc=0.4600\n",
      "Epoch 45 train_loss = 0.6715 val_loss=0.7170 val_acc=0.4600\n",
      "Epoch 46 train_loss = 0.6794 val_loss=0.7670 val_acc=0.4600\n",
      "Epoch 47 train_loss = 0.6716 val_loss=0.6632 val_acc=0.4600\n",
      "Epoch 48 train_loss = 0.6812 val_loss=0.7528 val_acc=0.4600\n",
      "Epoch 49 train_loss = 0.6773 val_loss=0.7008 val_acc=0.4600\n",
      "Epoch 50 train_loss = 0.6765 val_loss=0.7780 val_acc=0.4600\n",
      "Epoch 51 train_loss = 0.6942 val_loss=0.7342 val_acc=0.4600\n",
      "Epoch 52 train_loss = 0.6727 val_loss=0.6870 val_acc=0.4600\n",
      "Epoch 53 train_loss = 0.6771 val_loss=0.7094 val_acc=0.4600\n",
      "Epoch 54 train_loss = 0.6719 val_loss=0.6984 val_acc=0.4600\n",
      "Epoch 55 train_loss = 0.6621 val_loss=0.6884 val_acc=0.4600\n",
      "Epoch 56 train_loss = 0.6797 val_loss=0.7280 val_acc=0.4600\n",
      "Epoch 57 train_loss = 0.6765 val_loss=0.6936 val_acc=0.4600\n",
      "Epoch 58 train_loss = 0.6855 val_loss=0.7628 val_acc=0.4600\n",
      "Epoch 59 train_loss = 0.6844 val_loss=0.7032 val_acc=0.4600\n",
      "Epoch 60 train_loss = 0.6811 val_loss=0.7108 val_acc=0.4600\n",
      "Epoch 61 train_loss = 0.6688 val_loss=0.6818 val_acc=0.4600\n",
      "Epoch 62 train_loss = 0.6674 val_loss=0.7094 val_acc=0.4600\n",
      "Epoch 63 train_loss = 0.6804 val_loss=0.7108 val_acc=0.4600\n",
      "Epoch 64 train_loss = 0.6821 val_loss=0.6718 val_acc=0.4600\n",
      "Epoch 65 train_loss = 0.6866 val_loss=0.6870 val_acc=0.4600\n",
      "Epoch 66 train_loss = 0.6744 val_loss=0.6632 val_acc=0.4600\n",
      "Epoch 67 train_loss = 0.6793 val_loss=0.6632 val_acc=0.4600\n",
      "Epoch 68 train_loss = 0.6728 val_loss=0.6622 val_acc=0.4600\n",
      "Epoch 69 train_loss = 0.6751 val_loss=0.6718 val_acc=0.4600\n",
      "Epoch 70 train_loss = 0.6779 val_loss=0.7356 val_acc=0.4600\n",
      "Epoch 71 train_loss = 0.6749 val_loss=0.6784 val_acc=0.4600\n",
      "Epoch 72 train_loss = 0.6749 val_loss=0.7146 val_acc=0.4600\n",
      "Epoch 73 train_loss = 0.6795 val_loss=0.7184 val_acc=0.4600\n",
      "Epoch 74 train_loss = 0.6788 val_loss=0.7004 val_acc=0.4600\n",
      "Epoch 75 train_loss = 0.6840 val_loss=0.7032 val_acc=0.4600\n",
      "Epoch 76 train_loss = 0.6803 val_loss=0.6908 val_acc=0.4600\n",
      "Epoch 77 train_loss = 0.6697 val_loss=0.7056 val_acc=0.4600\n",
      "Epoch 78 train_loss = 0.6862 val_loss=0.7246 val_acc=0.4600\n",
      "Epoch 79 train_loss = 0.6768 val_loss=0.6898 val_acc=0.4600\n",
      "Epoch 80 train_loss = 0.6793 val_loss=0.6660 val_acc=0.4600\n",
      "Epoch 81 train_loss = 0.6802 val_loss=0.7312 val_acc=0.4600\n",
      "Epoch 82 train_loss = 0.6787 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 83 train_loss = 0.6775 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 84 train_loss = 0.6788 val_loss=0.7156 val_acc=0.4600\n",
      "Epoch 85 train_loss = 0.6817 val_loss=0.7418 val_acc=0.4600\n",
      "Epoch 86 train_loss = 0.6765 val_loss=0.7618 val_acc=0.4600\n",
      "Epoch 87 train_loss = 0.6812 val_loss=0.7118 val_acc=0.4600\n",
      "Epoch 88 train_loss = 0.6849 val_loss=0.7308 val_acc=0.4600\n",
      "Epoch 89 train_loss = 0.6806 val_loss=0.7046 val_acc=0.4600\n",
      "Epoch 90 train_loss = 0.6844 val_loss=0.7546 val_acc=0.4600\n",
      "Epoch 91 train_loss = 0.6686 val_loss=0.6660 val_acc=0.4600\n",
      "Epoch 92 train_loss = 0.6869 val_loss=0.6718 val_acc=0.4600\n",
      "Epoch 93 train_loss = 0.6786 val_loss=0.7294 val_acc=0.4600\n",
      "Epoch 94 train_loss = 0.6608 val_loss=0.7232 val_acc=0.4600\n",
      "Epoch 95 train_loss = 0.6732 val_loss=0.6908 val_acc=0.4600\n",
      "Epoch 96 train_loss = 0.6728 val_loss=0.6794 val_acc=0.4600\n",
      "Epoch 97 train_loss = 0.6756 val_loss=0.7866 val_acc=0.4600\n",
      "Epoch 98 train_loss = 0.6853 val_loss=0.7580 val_acc=0.4600\n",
      "Epoch 99 train_loss = 0.6627 val_loss=0.6632 val_acc=0.4600\n",
      "Epoch 100 train_loss = 0.6784 val_loss=0.7708 val_acc=0.4600\n"
     ]
    }
   ],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
